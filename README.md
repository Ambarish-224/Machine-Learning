# üëè Pre- requisites to Machine Learning
    1Ô∏è‚É£ Python Basics
        a. Python basics :- variables,list,sets,tuples,loops,functions, lambda functions,dictionary, input
        b. Python Oops
        c. File and Error Handling - hello.txt, something.txt, data.json,created.json
        d. Iteration Protocol and Generators
    2Ô∏è‚É£ Data Acquisition
        a. Data Acquisition using Beautiful Soup 
        b. Data Acquisition using Web APIs
    3Ô∏è‚É£ Python Libraries :-
        a. Numpy
        b. Matplotlib
        c. Seaborn
        d. Pandas
    4Ô∏è‚É£ Feature Selection and Extraction
        a.Feature Selection - Chi2 test, randomforest classifier
        b.Feature Extraction - Principal Component Analysis
    5Ô∏è‚É£  Data Analysis
           1Ô∏è‚É£ Steps in Data Analytics Projects, Data Analytics tasks and methods, Data Gathering and Preparation:
                a. Data Formats, Parsing and Transformation, Scalability and Real-time Issues; Data Cleaning
                b. Consistency Checking, Heterogeneous and Missing Data, Data Transformation and Segmentation; 
           2Ô∏è‚É£ Exploratory Analysis:
                a. Descriptive and comparative statistics, Hypothesis testing, Statistical Inference.
  # üî• Machine-Learning   
    1Ô∏è‚É£ K- Nearest Neighbour:-
           - Theory
           - Implementation
           
    2Ô∏è‚É£ Linear Regression
          - What is Linear Regression
          - What is gradient descent
          - Implementation of gradient descent
          - Making predictions on data set
          - Contour and Surface Plots
          - Visualizing Loss function and Gradient Descent
          - Multivariate Linear Regression on boston housing dataset
          - Optimization of Multivariate Linear Regression 
          - Using Scikit Learn for Linear Regression  
          - Closed Form Solution
          - LOWESS - Locally Weighted Regression
          - Maximum Likelihood Estimation
          
     3Ô∏è‚É£ Logistic Regression
          - Hypothesis function
          -  Log Loss
          -  Proof of Log loss by MLE
          -  Gradient Descent Update rule for Logistic Regression
          - Gradient Descent Implementation of Logistic Regression
          - Sk-Learn Implementation of Logistic Regression on chemical classification dataset.
          
    4Ô∏è‚É£ Natural Language Processing 
          - Bag of Words Pipeline 
          - Tokenization and Stopword Removal
          - Regex based Tokenization
          - Stemming & Lemmatization
          - Constructing Vocab
          - Vectorization with Stopwords Removal
          - Bag of Words Model- Unigram, Bigram, Trigram, n- gram
          - TF-IDF Normalization     
          
    5Ô∏è‚É£ Naive Bayes
          - Bayes Theorem Formula 
          - Bayes Theorem - Spam or not
          - Bayes Theorem - Disease or not
          - Mushroom Classification
          - Text Classification
          - Laplace Smoothing
          - Multivariate Bernoulli Naive Bayes
          - Multivariate Event Model Naive Bayes
          -  Multivariate Bernoulli Naive Bayes vs Multivariate Event Model Naive Bayes
          -  Gaussian Naive Bayes
          
    6Ô∏è‚É£ Decision Tree and Random Forest Classifier
          - Entropy
          - Information Gain
          - Process Kaggle Tiatnic Dataset 
          - Implementation of Information Gain
          - Implementation of Decision Tree
          - Making Predicitions
          - Decision Trees using Sci-kit Learn
          - Random Forest Ensembles
       
          
          
          
                 
   # üíØ Mathematics required for Machine Learning
        1Ô∏è‚É£ Statistics:
            a. Measures of central tendency ‚Äì mean, median, mode
            b. measures of dispersion ‚Äì mean deviation, standard deviation, quartile deviation, skewness and kurtosis.
            c. Correlation coefficient, regression, least squares principles of curve fitting
        2Ô∏è‚É£ Probability:
            a. Introduction, finite sample spaces, conditional probability and independence, Bayes‚Äô theorem, one dimensional random variable, mean, variance.
        3Ô∏è‚É£ Linear Algebra :- scalars,vectors,matrices,tensors.transpose,broadcasting,matrix multiplication, hadamard product,norms,determinants, solving linear equations
    
  # üìö Handwritten notes with proper implementation of each algorithm from scratch 
       ‚úî KNN 
       - In depth theory with example.
 
       ‚úî Linear Regression
       -  Indepth intution of maths required of Linear Regression
       -  Derivation of Gradient Descent for Univariate Linear Regression
       - Surface and Contour Plots
       - Visualization of Loss function, gradient descent and values of theta
       - Multivariate Linear Regression on boston housing dataset
       - Optimization of Multivariate Linear Regression 
       - Closed Form solution derivation
       - Locally Weighted Regression Derivation
       - Maximum Likelihood Estimation for Linear Regression
       
      ‚úî Logitstic Regression 
       - Hypothesis function
       -  Log Loss
       -  Proof of Log loss by MLE
       -  Gradient Descent Update rule for Logistic Regression
       
       ‚úî Feature Selection and Extraction
       - Feature Selection
       - Feature Extraction - Principal Component Analysis
       
       ‚úî Naive Bayes
         - Bayes Theorem Formula 
         - Bayes Theorem - Spam or not
         - Bayes Theorem - Disease or not
         - Mushroom Classification
         - Text Classification
         - Laplace Smoothing
         - Multivariate Bernoulli Naive Bayes
         - Multivariate Event Model Naive Bayes
         -  Multivariate Bernoulli Naive Bayes vs Multivariate Event Model Naive Bayes
         -  Gaussian Naive Bayes
  
  # üôå Projects :- 
        üîÖ Movie Recommendation System
        üîÖ Diabetes Classification 
        üîÖ Handwriting Recognition
        üîÖ Linkedin Webscraping
        üîÖ Air Pollution Regression
 
#### Machine Learning is best done with proper mathematical derivations and explained code but for revision and quick work using sklearn can be incredibly helpful. 
### This series contains implementation of every algorithm in sklearn to give you a quick revision of its working and concept.
# Machine Learning Short Notes :- 
       ‚úÖ 1. What is Machine Learning?
       - Supervised Learning and it types
       - Unsupervised Learning and its types

       ‚úÖ 2. Linear Regression using Single Variable 
       - Homeprices Prediction
       - Per Capita Income predicition for Canada 

       ‚úÖ 3. Linear Regression using Multiple variables
       - Homeprices Prediction
       - Car Prices Pediction
       - Best hiring choice 

       ‚úÖ 4. Gradient Descent and Cost Function

       ‚úÖ 5. Dummy Variable and One Hot Encoding

       ‚úÖ 6. Logistic Regression - Binary Classification
        - Handwriting Recognition 

       ‚úÖ 7. Logistic Regression - Multiclass Classification
       - IRIS Dataset 
